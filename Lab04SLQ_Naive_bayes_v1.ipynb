{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hny_S0l1kLeS"
      },
      "source": [
        "# 2CS SIL2-SIQ2 Lab04. Naïve Bayes\n",
        "\n",
        "<p style='text-align: right;font-style: italic;'>Designed by: Dr. Abdelkrime Aries</p>\n",
        "\n",
        "In this lab, we will learn about two generative models:\n",
        "- Naïve Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgFhRT5UkLeT"
      },
      "source": [
        "**Team:**\n",
        "- **Member 01**: Bougrine Nermine\n",
        "- **Member 02**: Benni soundos\n",
        "- **Group**: SIL2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vOz7X0iOkLeU",
        "outputId": "9eb66273-8a97-466e-e3be-cdf1f0dd5554"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import sys, timeit\n",
        "from typing          import Tuple, List, Type\n",
        "from collections.abc import Callable\n",
        "\n",
        "sys.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "866jKG7MkLeV",
        "outputId": "fbf9d5f9-24ea-42b4-ba60-8638a62eac6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.25.2', '2.0.3', '3.7.1')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import numpy             as np\n",
        "import pandas            as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "np.__version__, pd.__version__, matplotlib.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NEDi_PM-kLeV",
        "outputId": "4ccae470-0317-41e7-9cef-4f7861def002"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.2.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "from sklearn.naive_bayes   import CategoricalNB\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics       import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection         import train_test_split\n",
        "from sklearn.naive_bayes             import MultinomialNB, GaussianNB\n",
        "from sklearn.linear_model            import LogisticRegression\n",
        "from sklearn.tree                    import DecisionTreeClassifier\n",
        "from sklearn.metrics                 import precision_score, recall_score\n",
        "import timeit\n",
        "\n",
        "\n",
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8i1RQj1kLeW"
      },
      "source": [
        "## I. Algorithms implementation\n",
        "\n",
        "In this section, we will try to implement multinomial Naive Bayes.\n",
        "\n",
        "\n",
        "**>> Try to use \"numpy\" which will save a lot of time and effort**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg_qLJlKkLeW",
        "outputId": "b0c2ea91-e227-4976-a559-9d829e787843"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Dataset play\n",
        "\n",
        "# outlook & temperature & humidity & windy\n",
        "Xplay = np.array([\n",
        "    ['sunny'   , 'hot' , 'high'  , 'no'],\n",
        "    ['sunny'   , 'hot' , 'high'  , 'yes'],\n",
        "    ['overcast', 'hot' , 'high'  , 'no'],\n",
        "    ['rainy'   , 'mild', 'high'  , 'no'],\n",
        "    ['rainy'   , 'cool', 'normal', 'no'],\n",
        "    ['rainy'   , 'cool', 'normal', 'yes'],\n",
        "    ['overcast', 'cool', 'normal', 'yes'],\n",
        "    ['sunny'   , 'mild', 'high'  , 'no'],\n",
        "    ['sunny'   , 'cool', 'normal', 'no'],\n",
        "    ['rainy'   , 'mild', 'normal', 'no'],\n",
        "    ['sunny'   , 'mild', 'normal', 'yes'],\n",
        "    ['overcast', 'mild', 'high'  , 'yes'],\n",
        "    ['overcast', 'hot' , 'normal', 'no'],\n",
        "    ['rainy'   , 'mild', 'high'  , 'yes']\n",
        "])\n",
        "\n",
        "Yplay = np.array([\n",
        "    'no',\n",
        "    'no',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'no',\n",
        "    'yes',\n",
        "    'no',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'no'\n",
        "])\n",
        "\n",
        "len(Xplay), len(Yplay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew01JHEfkLeW"
      },
      "source": [
        "### I.1. Prior probability\n",
        "\n",
        "Given an output list $Y$, the probability of each class $c_k$ is estimated as:\n",
        "$$p(c_k) = log\\frac{|\\{y / y \\in Y \\text{ et } y = c_k\\}|}{|Y|}$$\n",
        "\n",
        "Our function must return two lists:\n",
        "- One containing the names of unique classes.\n",
        "- Another containing probabilities of unique classes of the first list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JtR2O7gEkLeW",
        "outputId": "2867ec82-af43-4769-da5c-f890c1ae03ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['no', 'yes'], dtype='<U3'), array([-1.02961942, -0.44183275]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: Prior probability\n",
        "def fit_prior(Y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    cls  = np.unique(Y) # vocabulary\n",
        "    prior = []\n",
        "\n",
        "    # Count occurrences of each class\n",
        "    class_counts = np.array([np.count_nonzero(Y == c) for c in cls])\n",
        "\n",
        "    # Calculate prior probabilities using the formula\n",
        "    prior = np.log(class_counts / len(Y))\n",
        "    return cls, np.array(prior)\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# (array(['no', 'yes'], dtype='<U3'), array([-1.02961942, -0.44183275]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "fit_prior(Yplay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkYatXcPkLeW"
      },
      "source": [
        "### I.2. Multinomial Likelihood probability\n",
        "\n",
        "Given:\n",
        "- $A$: a categorical feature\n",
        "- $V$: unique values of this feature (feature's categories)\n",
        "- $Y$: the ouput\n",
        "- $C$: the classes\n",
        "- $\\alpha$: smoothing factor\n",
        "\n",
        "calculate the log likelihood:\n",
        "$$ \\log p(A=v|Y=c_k) = \\log(|\\{ y \\in Y / y = c_k \\text{ and } A = v\\}| + \\alpha) - \\log(|\\{y = c_k\\}| + \\alpha * |V|)$$\n",
        "\n",
        "The function must:\n",
        "- add a token \"\\<UNK\\>\" to $V$\n",
        "- return feature's categories (vocabulary) $V$\n",
        "- return a matrix where rows are $V$ and colums are $C$ containing the log probability $p(V|C)$\n",
        "- when alpha=0 and v=UNK, we will have an error, in this case we will consider log probability as $-\\infty$\n",
        "- when the probability is 0, we will consider log probability as $-\\infty$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y4GAICwjkLeW",
        "outputId": "41f0312b-58db-4e7a-ff05-a40976871e3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array(['overcast', 'rainy', 'sunny', '<UNK>'], dtype='<U8'),\n",
              "  array([[       -inf, -0.81093022],\n",
              "         [-0.91629073, -1.09861229],\n",
              "         [-0.51082562, -1.5040774 ],\n",
              "         [       -inf,        -inf]])),\n",
              " (array(['overcast', 'rainy', 'sunny', '<UNK>'], dtype='<U8'),\n",
              "  array([[-2.19722458, -0.95551145],\n",
              "         [-1.09861229, -1.178655  ],\n",
              "         [-0.81093022, -1.46633707],\n",
              "         [-2.19722458, -2.56494936]])))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# TODO: Multinomial Likelihood probability\n",
        "def fit_likelihood(A: np.ndarray,\n",
        "                   Y: np.ndarray,\n",
        "                   C: np.ndarray,\n",
        "                   alpha: float = 0.) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    # Add \"<UNK>\" token to V\n",
        "    V = np.unique(A)\n",
        "    V = np.concatenate([V, ['<UNK>']])\n",
        "\n",
        "    # Initialize likelihood matrix\n",
        "    likelihood = np.zeros((len(V), len(C)))\n",
        "\n",
        "    # Count occurrences of A=v for each class C=ck\n",
        "    for i, ck in enumerate(C):\n",
        "        for j, v in enumerate(V):\n",
        "            # Calculate numerator and denominator for log probability\n",
        "            numerator = np.count_nonzero((Y == ck) & (A == v)) + alpha\n",
        "            denominator = np.count_nonzero(Y == ck) + alpha * len(V)\n",
        "\n",
        "            # Calculate log probability\n",
        "            if numerator == 0:\n",
        "                likelihood[j, i] = float('-inf')  # Probability is 0, log probability is -∞\n",
        "            else:\n",
        "                likelihood[j, i] = np.log(numerator / denominator)\n",
        "\n",
        "    return V, likelihood\n",
        "\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# ((array(['overcast', 'rainy', 'sunny', '<UNK>'], dtype='<U8'),\n",
        "#  array([[ -inf, -0.81093022],\n",
        "# [-0.91629073, -1.09861229],\n",
        "#             [-0.51082562, -1.5040774 ],\n",
        "#             [ -inf, -inf]])),\n",
        "# (array(['overcast', 'rainy', 'sunny', '<UNK>'], dtype='<U8'),\n",
        "#  array([[-2.19722458, -0.95551145],\n",
        "#              [-1.09861229, -1.178655 ],\n",
        "#              [-0.81093022, -1.46633707],\n",
        "#              [-2.19722458, -2.56494936]])))-------------------------------\n",
        "C_t = np.array(['no', 'yes'])\n",
        "fit_likelihood(Xplay[:, 0], Yplay, C_t), fit_likelihood(Xplay[:, 0], Yplay, C_t, alpha=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzdXUv9VkLeX"
      },
      "source": [
        "### I.3. Model training\n",
        "\n",
        "**Nothing to code here, although you have to know how it functions for next use**\n",
        "\n",
        "Given a feature $X_j$, a value $v \\in X_j$ and a class $c_k$, the likeelihood is calculated:\n",
        "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ and } X_j = v\\}|}{|\\{y = c_k\\}|}$$\n",
        "\n",
        "This function aims to generate parameters $\\theta$.\n",
        "In our case, paramters are diffrent from those of *logistic regrssion*.\n",
        "They are a dictionary (map) with two entries:\n",
        "- \"prior\" key having a dictionary as value, having \"v\" a list of values and \"p\" a list of their respective probabilities.\n",
        "- \"likelihood\" a list of dictinaries reprsnting statistics of each feature (the same order of $X$ features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SbjFqipSkLeX",
        "outputId": "97fd7726-7334-49f3-9073-3fe803e82d8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prior': {'v': array(['no', 'yes'], dtype='<U3'),\n",
              "  'p': array([-1.02961942, -0.44183275])},\n",
              " 'likelihood': [{'v': array(['overcast', 'rainy', 'sunny', '<UNK>'], dtype='<U8'),\n",
              "   'p': array([[-2.19722458, -0.95551145],\n",
              "          [-1.09861229, -1.178655  ],\n",
              "          [-0.81093022, -1.46633707],\n",
              "          [-2.19722458, -2.56494936]])},\n",
              "  {'v': array(['cool', 'hot', 'mild', '<UNK>'], dtype='<U8'),\n",
              "   'p': array([[-1.5040774 , -1.178655  ],\n",
              "          [-1.09861229, -1.46633707],\n",
              "          [-1.09861229, -0.95551145],\n",
              "          [-2.19722458, -2.56494936]])},\n",
              "  {'v': array(['high', 'normal', '<UNK>'], dtype='<U8'),\n",
              "   'p': array([[-0.47000363, -1.09861229],\n",
              "          [-1.38629436, -0.5389965 ],\n",
              "          [-2.07944154, -2.48490665]])},\n",
              "  {'v': array(['no', 'yes', '<UNK>'], dtype='<U8'),\n",
              "   'p': array([[-0.98082925, -0.5389965 ],\n",
              "          [-0.69314718, -1.09861229],\n",
              "          [-2.07944154, -2.48490665]])}]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "def fit_NB(X: np.ndarray,\n",
        "        Y: np.ndarray,\n",
        "        alpha=0.\n",
        "        ) -> object:\n",
        "\n",
        "    Theta   = {'prior': {}, 'likelihood': []}\n",
        "\n",
        "    Theta['prior']['v'], Theta['prior']['p'] = fit_prior(Y)\n",
        "\n",
        "    for j in range(X.shape[1]):\n",
        "        likelihood = {}\n",
        "        likelihood['v'], likelihood['p'] = fit_likelihood(X[:, j], Y, Theta['prior']['v'], alpha=alpha)\n",
        "        Theta['likelihood'].append(likelihood)\n",
        "\n",
        "    return Theta\n",
        "\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# {'prior': {'v': array(['no', 'yes'], dtype='<U3'),\n",
        "#    'p': array([-1.02961942, -0.44183275])},\n",
        "#    'likelihood': [{'v': array(['overcast', 'rainy', 'sunny', '<UNK>'], dtype='<U8'),\n",
        "#    'p': array([[-2.19722458, -0.95551145],\n",
        "#                     [-1.09861229, -1.178655 ],\n",
        "#                     [-0.81093022, -1.46633707],\n",
        "#                     [-2.19722458, -2.56494936]])},\n",
        "#     {'v': array(['cool', 'hot', 'mild', '<UNK>'], dtype='<U8'),\n",
        "#       'p': array([[-1.5040774 , -1.178655 ],\n",
        "#                        [-1.09861229, -1.46633707],\n",
        "#                        [-1.09861229, -0.95551145],\n",
        "#                        [-2.19722458, -2.56494936]])},\n",
        "#     {'v': array(['high', 'normal', '<UNK>'], dtype='<U8'),\n",
        "#       'p': array([[-0.47000363, -1.09861229],\n",
        "#                        [-1.38629436, -0.5389965 ],\n",
        "#                        [-2.07944154, -2.48490665]])},\n",
        "#     {'v': array(['no', 'yes', '<UNK>'], dtype='<U8'),\n",
        "#       'p': array([[-0.98082925, -0.5389965 ],\n",
        "#                        [-0.69314718, -1.09861229],\n",
        "#                        [-2.07944154, -2.48490665]])}]\n",
        "#---------------------------------------------------------------------\n",
        "Theta_play = fit_NB(Xplay, Yplay, alpha=1)\n",
        "\n",
        "Theta_play"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJgyTpA8kLeY"
      },
      "source": [
        "### I.4. Multinomial prediction\n",
        "Let's examine prediction equation:\n",
        "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n",
        "\n",
        "Our goal is to calculate approximate probabilities of all classes given a sample like indicated in the next equation:\n",
        "$$P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n",
        "\n",
        "- Given one sample $x$, we have to return a list of probabilities.\n",
        "- If prior=false, we must not consider prior probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lYKXhLl-kLeY",
        "outputId": "9c0ce267-5d0b-4cb8-d031-691d75cb598d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-6.81036293, -5.8230459 ]), array([-4.68213123, -3.99491878]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# You can use this function in the next implimentation\n",
        "# It takes a list of unique values V and a given value v\n",
        "# It returns the position of v in V\n",
        "# If v does not exist in V, it rturns -1\n",
        "def find_idx(V: np.ndarray, v: str) -> int:\n",
        "    k = np.argwhere(V == v).flatten()\n",
        "    if len(k):\n",
        "        return k[0]\n",
        "    return -1\n",
        "\n",
        "# TODO: Prediction\n",
        "def predict_NB_1(Xi: np.ndarray, Theta: dict, add_prior: bool = True) -> List[float]:\n",
        "    # Extract prior probabilities and likelihood information from Theta\n",
        "    prior_probs = Theta['prior']['p']\n",
        "    likelihood_info = Theta['likelihood']\n",
        "    classes = len(prior_probs)  # Number of classes\n",
        "\n",
        "    # Initialize array to store log probabilities\n",
        "    log_probs = np.zeros(classes)\n",
        "\n",
        "    # If add_prior is True, add prior probabilities to log_probs\n",
        "    if add_prior:\n",
        "        log_probs += prior_probs\n",
        "\n",
        "    # Iterate over each feature in the sample Xi\n",
        "    for i, feature in enumerate(Xi):\n",
        "        # Find the index of the feature value in the likelihood_info\n",
        "        idx = find_idx(likelihood_info[i]['v'], feature)\n",
        "\n",
        "        # If the feature value is not found, use the index for '<UNK>'\n",
        "        if idx == -1:\n",
        "            idx = find_idx(likelihood_info[i]['v'], '<UNK>')\n",
        "\n",
        "        # Add the log probability of the feature value to log_probs\n",
        "        log_probs += likelihood_info[i]['p'][idx]\n",
        "\n",
        "    return log_probs\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "#(array([-6.81036293, -5.8230459 ]), array([-4.68213123, -3.99491878]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "X_t = np.array([\n",
        "    ['rainy', 'cool', 'normal', 'yes'],\n",
        "    ['snowy', 'cool', 'normal', 'yes'],\n",
        "    ['sunny', 'hot' , 'normal', 'no']\n",
        "])\n",
        "\n",
        "predict_NB_1(X_t[1, :], Theta_play), predict_NB_1(X_t[0, :], Theta_play, add_prior=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfo7qnMskLeY"
      },
      "source": [
        "### I.5. Final product\n",
        "\n",
        "**>> Nothing to code here**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RvwpswHHkLeY",
        "outputId": "ff85cabd-f14d-4309-e4c6-8297564edfc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['yes', 'yes', 'yes'], dtype='<U3'),\n",
              " array([[-5.71175064, -4.43675153],\n",
              "        [-6.81036293, -5.8230459 ],\n",
              "        [-5.30628554, -4.45249989]]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "class OurCategoricalNB(object):\n",
        "\n",
        "    def fit(self, X, Y, alpha=0.):\n",
        "        self.Theta = fit_NB(X, Y, alpha=alpha)\n",
        "\n",
        "    def predict(self, X, add_prior=True, prob=False):\n",
        "        Y_pred = []\n",
        "        for i in range(len(X)):\n",
        "            Y_pred.append(predict_NB_1(X[i,:], self.Theta, add_prior=add_prior))\n",
        "\n",
        "        Y_pred = np.array(Y_pred)\n",
        "\n",
        "        if prob:\n",
        "            return Y_pred\n",
        "\n",
        "        return np.choose(np.argmax(Y_pred, axis=1), self.Theta['prior']['v'])\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# array(['yes', 'yes', 'yes'], dtype='<U3'),\n",
        "#  array([[-5.71175064, -4.43675153],\n",
        "#              [-6.81036293, -5.8230459 ],\n",
        "#              [-5.30628554, -4.45249989]]))\n",
        "cnb = OurCategoricalNB()\n",
        "cnb.fit(Xplay, Yplay, alpha=1)\n",
        "X_t = np.array([\n",
        "    ['rainy', 'cool', 'normal', 'yes'],\n",
        "    ['snowy', 'cool', 'normal', 'yes'],\n",
        "    ['sunny', 'hot' , 'normal', 'no']\n",
        "])\n",
        "\n",
        "cnb.predict(X_t), cnb.predict(X_t, prob=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_sI-XUIkLeY"
      },
      "source": [
        "## II. Application and Analysis\n",
        "\n",
        "In this section, we will test different concepts by running an experiment, formulating a hypothesis and trying to justify it.\n",
        "\n",
        "### II.1. Prior probability\n",
        "\n",
        "We want to test the effect of prior probability.\n",
        "To do this, we trained two models:\n",
        "1. With prior probability\n",
        "1. Without prior probability (It considers a uniform distribution of classes)\n",
        "\n",
        "To test whether the models have adapted well to the training dataset, we will test them on the same dataset and calculate the classification ratio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yJz0-TWrkLeZ",
        "outputId": "d6ba9862-5f75-40de-afb5-c6307a3ed5c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Considring prior probability\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "No prior probability\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.67      0.80      0.73         5\n",
            "         yes       0.88      0.78      0.82         9\n",
            "\n",
            "    accuracy                           0.79        14\n",
            "   macro avg       0.77      0.79      0.78        14\n",
            "weighted avg       0.80      0.79      0.79        14\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nb_withPrior     = CategoricalNB(alpha=1.0, fit_prior=True )\n",
        "nb_noPrior       = CategoricalNB(alpha=1.0, fit_prior=False)\n",
        "\n",
        "enc         = OrdinalEncoder()\n",
        "Xplay_tf    = enc.fit_transform(Xplay)\n",
        "nb_withPrior.fit(Xplay_tf, Yplay)\n",
        "nb_noPrior.fit(Xplay_tf, Yplay)\n",
        "\n",
        "Ypred_withPrior = nb_withPrior.predict(Xplay_tf)\n",
        "Ypred_noPrior = nb_noPrior.predict(Xplay_tf)\n",
        "\n",
        "\n",
        "print( 'Considring prior probability'  )\n",
        "print(classification_report(Yplay, Ypred_withPrior))\n",
        "\n",
        "print( 'No prior probability'  )\n",
        "print(classification_report(Yplay, Ypred_noPrior))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiTv9x48kLeZ"
      },
      "source": [
        "**TODO: Analyze the results**\n",
        "\n",
        "1. What do you notice, indicating if prior probability is useful in this case?\n",
        "1. How does this probability affect the outcome?\n",
        "1. When are we sure that using this probability is unnecessary?\n",
        "\n",
        "**Answer**\n",
        "\n",
        "1. The overall performance of the model with prior probabilities was better in terms of accuracy, precision, recall, and f1-score. So using prior probability is useful in this case.\n",
        "1. Using prior probability the model has learned and incorporated class distribution from the training data effectively. In fact, the prior probabilities help the model to make better predictions by leveraging the inherent distribution of classes in the training set. This is particularly useful when some classes are more common than others.\n",
        "1. If the training dataset is perfectly balanced (equal representation of all classes), using prior probabilities may not significantly affect performance. In such cases, a uniform distribution aligns with the natural class distribution, rendering prior probabilities unnecessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w_HFyevkLeZ"
      },
      "source": [
        "### II.2. Smoothing\n",
        "\n",
        "We want to test the Lidstone smoothing's effect.\n",
        "To do this, we trained three models:\n",
        "1. alpha = 1 (Laplace smoothing)\n",
        "1. alpha = 0.5\n",
        "1. alpha = 0 (without smoothing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "O6e7UVkCkLeZ",
        "outputId": "b94ccb87-c1c5-486e-d2d1-64beb88319b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha = 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "Alpha = 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "Alpha = 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "NBC_10 = CategoricalNB(alpha = 1.0 )\n",
        "NBC_05 = CategoricalNB(alpha = 0.5 )\n",
        "NBC_00 = CategoricalNB(alpha = 0.0 )\n",
        "\n",
        "NBC_10.fit( Xplay_tf,   Yplay )\n",
        "NBC_05.fit( Xplay_tf,   Yplay )\n",
        "NBC_00.fit( Xplay_tf,   Yplay )\n",
        "\n",
        "Y_10   = NBC_10.predict(Xplay_tf)\n",
        "Y_05   = NBC_05.predict(Xplay_tf)\n",
        "Y_00   = NBC_00.predict(Xplay_tf)\n",
        "\n",
        "\n",
        "print(          'Alpha = 1.0'             )\n",
        "print(classification_report(Yplay, Y_10))\n",
        "\n",
        "print(          'Alpha = 0.5'             )\n",
        "print(classification_report(Yplay, Y_05))\n",
        "\n",
        "print(          'Alpha = 0.0'             )\n",
        "print(classification_report(Yplay, Y_00))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO2N0PjFkLeZ"
      },
      "source": [
        "**TODO: Analyze the results**\n",
        "\n",
        "1. What do you notice, indicating if smoothing affects performance in this case?\n",
        "1. Based on the past answeer, Why?\n",
        "1. Why do we get a \"RuntimeWarning: divide by zero\" error?\n",
        "1. What is the benefit of smoothing (generally; not just for this case)?\n",
        "\n",
        "**Answer**\n",
        "\n",
        "1. From the output, all three models -whether using Laplace smoothing, partial smoothing, or no smoothing- produced identical classification results. Each model achieved an accuracy of 93%, with similar precision, recall, and f1-score. So in this dataset, smoothing does not impact performance.\n",
        "1. It may be because the training data effectively represents the test data, with little need for additional smoothing to handle unseen cases.\n",
        "1. A \"RuntimeWarning: divide by zero\" can occur in Naive Bayes when calculating conditional probabilities if a feature-class combination has zero counts. Without smoothing, a zero probability can lead to computational issues, as the logarithm of zero is undefined, causing division by zero in calculations.\n",
        "1. Benefits of smoothing generally :\n",
        "* Avoids Zero Probabilities: By adding a small constant to each count, smoothing ensures that all probabilities are non-zero, preventing computational issues and undefined results.\n",
        "* Improves Generalization: Smoothing helps the model handle unseen data by ensuring that even unseen feature-class combinations have a small, non-zero probability.\n",
        "* Reduces Overfitting: Smoothing can mitigate overfitting by introducing a degree of regularization. It acts as a regularization technique, preventing the model from overfitting to exact matches in the training set.\n",
        "* Facilitates More Robust Predictions: Models with smoothing are less prone to extreme changes due to minor variations in the dataset, leading to more stable predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geBOX8LpkLea"
      },
      "source": [
        "### II.3. Naive Bayes performance\n",
        "\n",
        "Naive Bayes is known to generate powerful models when it comes to classifying textual documents.\n",
        "We want to test this proposition using spam detection over [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset) dataset.\n",
        "\n",
        "Each message is represented using term frequency (TF), where a word is considered as a feature.\n",
        "In this case, a message is represented by a vector of frequencies (how many times each word appeared in the message).\n",
        "We want to compare these models:\n",
        "1. Multinomial Naive Bayes (MNB)\n",
        "1. Gaussian Naive Bayes (GNB)\n",
        "1. Logistic Regression (LR)\n",
        "1. Decision Tree (DT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cIIspNffkLea",
        "outputId": "5bd93ff6-6396-4c25-c8da-f939d3934d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text class\n",
              "0  Go until jurong point, crazy.. Available only ...   ham\n",
              "1                      Ok lar... Joking wif u oni...   ham\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
              "3  U dun say so early hor... U c already then say...   ham\n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6189fa7b-7789-40f7-baca-ed6aa6723872\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6189fa7b-7789-40f7-baca-ed6aa6723872')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6189fa7b-7789-40f7-baca-ed6aa6723872 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6189fa7b-7789-40f7-baca-ed6aa6723872');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-20103ee3-4d33-4969-9e0e-8d77c3fad14d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20103ee3-4d33-4969-9e0e-8d77c3fad14d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-20103ee3-4d33-4969-9e0e-8d77c3fad14d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "messages",
              "summary": "{\n  \"name\": \"messages\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"Did u download the fring app?\",\n          \"Pass dis to all ur contacts n see wat u get! Red;i'm in luv wid u. Blue;u put a smile on my face. Purple;u r realy hot. Pink;u r so swt. Orange;i thnk i lyk u. Green;i realy wana go out wid u. Yelow;i wnt u bck. Black;i'm jealous of u. Brown;i miss you Nw plz giv me one color\",\n          \"Ok...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# reading the dataset\n",
        "messages = pd.read_csv('data/spam.csv', encoding='latin-1')\n",
        "# renaming features: text and class\n",
        "messages = messages.rename(columns={'v1': 'class', 'v2': 'text'})\n",
        "# keeping only these two features\n",
        "messages = messages.filter(['text', 'class'])\n",
        "\n",
        "messages.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vIh2iLm0kLea",
        "outputId": "532bc1f8-c46f-4ee0-b3cc-3084dbfc96b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Algorithm  Train time  Test time  Precision    Recall\n",
              "0  Multinomial Naive Bayes (MNB)    0.453153   0.024498   0.987179  0.927711\n",
              "1    Gaussian Naive Bayes  (GNB)    0.350758   0.070634   0.616667  0.891566\n",
              "2       Logistic Regression (LR)    1.493579   0.059163   0.986111  0.855422\n",
              "3             Decision Tree (DT)   11.375798   0.012747   0.915584  0.849398"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-401f48d9-3305-431d-9c3b-c44abae005d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Train time</th>\n",
              "      <th>Test time</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Multinomial Naive Bayes (MNB)</td>\n",
              "      <td>0.453153</td>\n",
              "      <td>0.024498</td>\n",
              "      <td>0.987179</td>\n",
              "      <td>0.927711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gaussian Naive Bayes  (GNB)</td>\n",
              "      <td>0.350758</td>\n",
              "      <td>0.070634</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>0.891566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression (LR)</td>\n",
              "      <td>1.493579</td>\n",
              "      <td>0.059163</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.855422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree (DT)</td>\n",
              "      <td>11.375798</td>\n",
              "      <td>0.012747</td>\n",
              "      <td>0.915584</td>\n",
              "      <td>0.849398</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-401f48d9-3305-431d-9c3b-c44abae005d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-401f48d9-3305-431d-9c3b-c44abae005d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-401f48d9-3305-431d-9c3b-c44abae005d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f447bec-2f15-4dd7-b2e2-fbdc9e5ee874\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f447bec-2f15-4dd7-b2e2-fbdc9e5ee874')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f447bec-2f15-4dd7-b2e2-fbdc9e5ee874 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"})\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Algorithm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Gaussian Naive Bayes  (GNB)\",\n          \"Decision Tree (DT)\",\n          \"Multinomial Naive Bayes (MNB)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.330047754938807,\n        \"min\": 0.3507584129999941,\n        \"max\": 11.375797596999973,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3507584129999941,\n          11.375797596999973,\n          0.45315301100004035\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027545808672854076,\n        \"min\": 0.012747248999971816,\n        \"max\": 0.07063428100002511,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.07063428100002511,\n          0.012747248999971816,\n          0.02449750599998879\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17635706648712396,\n        \"min\": 0.6166666666666667,\n        \"max\": 0.9871794871794872,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6166666666666667,\n          0.9155844155844156,\n          0.9871794871794872\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03626986318913342,\n        \"min\": 0.8493975903614458,\n        \"max\": 0.927710843373494,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.891566265060241,\n          0.8493975903614458,\n          0.927710843373494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "models = [\n",
        "    MultinomialNB(),\n",
        "    GaussianNB(),\n",
        "    LogisticRegression(solver='lbfgs'),\n",
        "    #solver=sag is slower; so I chose the fastest\n",
        "    DecisionTreeClassifier()\n",
        "]\n",
        "\n",
        "algos = [\n",
        "    'Multinomial Naive Bayes (MNB)',\n",
        "    'Gaussian Naive Bayes  (GNB)',\n",
        "    'Logistic Regression (LR)',\n",
        "    'Decision Tree (DT)'\n",
        "]\n",
        "\n",
        "perf = {\n",
        "    'train_time': [],\n",
        "    'test_time' : [],\n",
        "    'recall'    : [],\n",
        "    'precision' : []\n",
        "}\n",
        "\n",
        "\n",
        "msg_train, msg_test, Y_train, Y_test = train_test_split(messages['text'] ,\n",
        "                                                        messages['class'],\n",
        "                                                        test_size    = 0.2,\n",
        "                                                        random_state = 0  )\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "X_train          = count_vectorizer.fit_transform(msg_train).toarray()\n",
        "X_test           = count_vectorizer.transform    (msg_test ).toarray()\n",
        "\n",
        "\n",
        "for model in models:\n",
        "    # ==================================\n",
        "    # TRAIN\n",
        "    # ==================================\n",
        "    start_time = timeit.default_timer()\n",
        "    model.fit(X_train, Y_train)\n",
        "    perf['train_time'].append(timeit.default_timer() - start_time)\n",
        "\n",
        "    # ==================================\n",
        "    # TEST\n",
        "    # ==================================\n",
        "    start_time = timeit.default_timer()\n",
        "    Y_pred     = model.predict(X_test)\n",
        "    perf['test_time'].append(timeit.default_timer() - start_time)\n",
        "\n",
        "    # ==================================\n",
        "    # PERFORMANCE\n",
        "    # ==================================\n",
        "    # In here, we are interrested in \"spam\" class which is our positive class\n",
        "    perf['precision'].append(precision_score(Y_test, Y_pred, pos_label='spam'))\n",
        "    perf['recall'   ].append(recall_score   (Y_test, Y_pred, pos_label='spam'))\n",
        "\n",
        "\n",
        "pd.DataFrame({\n",
        "    'Algorithm' : algos,\n",
        "    'Train time': perf['train_time'],\n",
        "    'Test time' : perf['test_time'],\n",
        "    'Precision' : perf['precision'],\n",
        "    'Recall'    : perf['recall']\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbSo8K2skLea"
      },
      "source": [
        "**TODO: Analyze the results**\n",
        "\n",
        "1. What do you notice about training time? (order the algorithms)\n",
        "1. Why did we get these results based on the algorithms? (discuss each algorithm with respect to training time)\n",
        "1. What do you notice about the testing time? (order the algorithms)\n",
        "1. Why did we get these results based on the algorithms? (discuss each algorithm with respect to testing time)\n",
        "1. Why is the Gaussian model less efficient than the multinomial based on the nature of the two algorithms?\n",
        "1. Why is the Gaussian model less efficient than the multinomial based on the nature of the problem/data?\n",
        "\n",
        "**Answer**\n",
        "\n",
        "1. Observing the training times of different algorithms, we note the following :\n",
        "    Gaussian Naive Bayes (GNB) has the shortest training time among the algorithms, taking approximately 0.91 seconds.\n",
        "    Multinomial Naive Bayes (MNB) follows closely with a training time of around 0.96 seconds, slightly slower than GNB.\n",
        "    Logistic Regression (LR) exhibits a noticeable increase in training time compared to the previous algorithms, clocking in at approximately 3.14 seconds.\n",
        "    Decision Tree (DT) stands out as the slowest among the tested algorithms, requiring a considerable training time of about 21.07 seconds, which is approximately 10 times longer than Logistic Regression.\n",
        "1.\n",
        "Training times for each algorithm are affected by various factors such as algorithm complexity, training data size, and available computational resources:\n",
        "  Gaussian Naive Bayes (GNB):\n",
        "  GNB is known for its simplicity and computational efficiency due to its assumption of features following a Gaussian distribution.\n",
        "  Its training time is relatively short because it involves straightforward computations and minimal complexity.\n",
        "  Multinomial Naive Bayes (MNB):\n",
        "  MNB, used in text classification with word frequencies as features, has a slightly longer training time than GNB.\n",
        "  The increase in training time is because it deals with categorical data and computes probabilities based on frequency counts.\n",
        "  Logistic Regression (LR):\n",
        "  LR, a linear model suitable for binary and multiclass classification, requires optimizing parameters through techniques like gradient descent.\n",
        "  Its training time is longer than Naive Bayes due to the iterative process of optimizing model parameters.\n",
        "  Decision Tree (DT):\n",
        "  DTs are non-linear models that partition feature space based on decision rules.\n",
        "  Training a decision tree involves recursive data splitting, leading to longer training times, especially for large datasets or complex features.\n",
        "1. The testing time of the algorithms varies significantly . We observe that the Decision Tree (DT) algorithm has the shortest testing time, clocking in at 0.027847. Following closely is Logistic Regression (LR) with a testing time of 0.046821, slightly slower than DT (LR's speed is approximately 1.58 times that of DT). Multinomial Naive Bayes (MNB) comes next with a testing time of 0.097735, slightly slower than the preceding algorithms . Finally, Gaussian Naive Bayes (GNB) exhibits the longest testing time at 0.214974, approximately 7 times slower than DT.\n",
        "1.Testing time: Generally, the results are related to the size of the test dataset and the complexity of each algorithm. Here, since the size of the test data is the same, we focus on the complexity of running these algorithms to classify a message.\n",
        "\n",
        "  Decision Tree (DT): It has the shortest testing time because predictions are made by simply following a path in the tree, evaluating conditions at each node to decide the branch to take. Also, the decision tree has already been built during training, so it doesn't require additional calculations to make predictions.\n",
        "  Logistic Regression (LR): It has a slightly longer testing time compared to DT because it involves more complex calculations for predictions, which are proportional to the size of the test dataset. However, these calculations are primarily related to computing the weights for features and making predictions based on them.\n",
        "  Multinomial Naive Bayes (MNB): It has a longer testing time than the first two algorithms because testing is affected by the number of different words in the vocabulary used to train the model. A larger vocabulary leads to longer testing times as the model needs to perform calculations for each word in the vocabulary to make predictions.\n",
        "  Gaussian Naive Bayes (GNB): The testing time is slightly longer than the other algorithms due to the complexity of calculations required to make predictions from the Gaussian distribution.\n",
        "1. The Gaussian model is less efficient than the multinomial model in this case, based on the nature of the two algorithms (their assumptions and functioning):\n",
        "\n",
        "  The two algorithms are not suitable for the same type of data. The multinomial Naive Bayes (NBM) model is better suited for text classification tasks, such as spam detection in our case, because it can model discrete data like word counts in a simple, flexible, and efficient manner. It calculates frequencies by counting the occurrences of each word in the message and uses these frequencies as features for classification. Therefore, it is more suitable for spam detection as it can easily handle discrete features and model probability distributions using counts.\n",
        "\n",
        "  On the other hand, the Gaussian Naive Bayes (NBG) model assumes that data follows a Gaussian distribution, which may not be the case for textual data that is often highly dispersed. This assumption and the density calculation performed by this algorithm can make NBG less efficient than NBM in spam detection.\n",
        "1. The Gaussian model is less efficient than the multinomial model based on the nature of the problem/data:\n",
        "\n",
        "  Firstly, the Gaussian model is designed to handle continuous data following a Gaussian (or normal) distribution. If the data is discrete, such as word frequencies in spam classification, the multinomial model is more appropriate as it is specifically designed for processing discrete data.\n",
        "\n",
        "  Secondly, the distribution of word frequencies in textual data often follows a power law rather than a Gaussian distribution. This power law distribution means that most words occur very rarely, while a few occur very frequently. This distribution is not suited for Gaussian modeling as it does not follow a normal distribution. The multinomial model is better suited for modeling this distribution using word frequency counts.\n",
        "\n",
        "  Lastly, the Gaussian model can be sensitive to outliers as it relies on the mean and standard deviation of the data distribution. If outliers are present in the data, it can impact the model's performance. In contrast, the multinomial model is less sensitive to outliers as it is based on frequency counts rather than continuous values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "C6OAhtZ9kLea",
        "outputId": "e4674e7f-fbd7-4df6-d4fd-96d1ac31b6cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  _____    __                                              _               \n",
            " |_   _|  / _|                                            | |              \n",
            "   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \n",
            "   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \n",
            "  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \n",
            " |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \n",
            "                   __/ |                     __/ |                         \n",
            "                  |___/                     |___/                          \n",
            "  _     _       _            __                                            \n",
            " | |   | |     (_)          / _|                 _                         \n",
            " | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \n",
            " | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \n",
            " | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \n",
            "  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \n",
            "                                                |/                         \n",
            "                                                                           \n",
            "                                                                           \n",
            "                                                                           \n",
            "  _   _    ___    _   _      __ _   _ __    ___                            \n",
            " | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \n",
            " | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \n",
            "  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \n",
            "   __/ |                                                                   \n",
            "  |___/                                                                    \n",
            "                    _                                                __    \n",
            "                   | |                                            _  \\ \\   \n",
            "  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \n",
            " | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \n",
            " | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \n",
            " |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \n",
            "                                                                     /_/   \n",
            "                                                                           \n"
          ]
        }
      ],
      "source": [
        "print(\"  _____    __                                              _               \")\n",
        "print(\" |_   _|  / _|                                            | |              \")\n",
        "print(\"   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \")\n",
        "print(\"   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \")\n",
        "print(\"  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \")\n",
        "print(\" |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \")\n",
        "print(\"                   __/ |                     __/ |                         \")\n",
        "print(\"                  |___/                     |___/                          \")\n",
        "print(\"  _     _       _            __                                            \")\n",
        "print(\" | |   | |     (_)          / _|                 _                         \")\n",
        "print(\" | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \")\n",
        "print(\" | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \")\n",
        "print(\" | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \")\n",
        "print(\"  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \")\n",
        "print(\"                                                |/                         \")\n",
        "print(\"                                                                           \")\n",
        "print(\"                                                                           \")\n",
        "print(\"                                                                           \")\n",
        "print(\"  _   _    ___    _   _      __ _   _ __    ___                            \")\n",
        "print(\" | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \")\n",
        "print(\" | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \")\n",
        "print(\"  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \")\n",
        "print(\"   __/ |                                                                   \")\n",
        "print(\"  |___/                                                                    \")\n",
        "print(\"                    _                                                __    \")\n",
        "print(\"                   | |                                            _  \\ \\   \")\n",
        "print(\"  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \")\n",
        "print(\" | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \")\n",
        "print(\" | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \")\n",
        "print(\" |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \")\n",
        "print(\"                                                                     /_/   \")\n",
        "print(\"                                                                           \")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}